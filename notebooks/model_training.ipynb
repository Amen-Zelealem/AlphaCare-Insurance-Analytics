{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training and Evaluation\n",
    "\n",
    "After preprocessing the data and saving it to a CSV file, the next step is to build and evaluate various machine learning models. This section outlines the approach for model training, evaluation, and feature importance analysis, ensuring we achieve the best model for predicting insurance claims.\n",
    "\n",
    "### Objectives\n",
    "The main objectives of this report are to:\n",
    "- Document the complete process of training, evaluating, and interpreting machine learning models for predicting car insurance claims.\n",
    "- Utilize the preprocessed dataset to train various models.\n",
    "- Evaluate each model based on relevant metrics to identify the best-performing one.\n",
    "- Conduct SHAP (SHapley Additive exPlanations) analysis to explain feature importance and model predictions.\n",
    "\n",
    "### Model Training Approach\n",
    "1. **Data Preparation**: Load the preprocessed dataset and split it into training and testing sets.\n",
    "2. **Model Selection**: Choose various machine learning algorithms (e.g., Linear Regression, Random Forest, Gradient Boosting).\n",
    "3. **Training**: Fit the models on the training set.\n",
    "4. **Evaluation**: Assess model performance using metrics such as MAE, RMSE, R², and accuracy.\n",
    "5. **Feature Importance**: Use SHAP analysis to interpret model outputs and understand the impact of different features on predictions.\n",
    "\n",
    "### Conclusion\n",
    "This comprehensive approach ensures that we not only find the most effective model for predicting insurance claims but also understand the underlying factors that influence these predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb  # Ensure XGBoost is installed for advanced gradient boosting\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the 'scripts' directory to the Python path for module imports\n",
    "sys.path.append(os.path.abspath(os.path.join('..', 'scripts')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set options for pandas to display more columns and rows\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.max_rows', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress warnings for cleaner output\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Load the preprocessed data from CSV file\n",
    "df = pd.read_csv('../data/preprocessed_data.csv')\n",
    "print(\"Data loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target variable for model training\n",
    "X = df.drop(columns=['TotalPremium'])\n",
    "y = df['TotalPremium']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split into training and testing sets.\n"
     ]
    }
   ],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(\"Data split into training and testing sets.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for Linear Regression model training and evaluation\n",
    "def linear_regression(X_train, y_train, X_test, y_test):\n",
    "    model = LinearRegression()  # Initialize the Linear Regression model\n",
    "    model.fit(X_train, y_train)  # Fit the model to the training data\n",
    "    predictions = model.predict(X_test)  # Make predictions on the test set\n",
    "    mse = mean_squared_error(y_test, predictions)  # Calculate mean squared error\n",
    "    return model, mse  # Return the trained model and the error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for Decision Tree model training and evaluation\n",
    "def decision_tree(X_train, y_train, X_test, y_test):\n",
    "    model = DecisionTreeRegressor(random_state=42)  # Initialize the Decision Tree model\n",
    "    model.fit(X_train, y_train)  # Fit the model to the training data\n",
    "    predictions = model.predict(X_test)  # Make predictions on the test set\n",
    "    mse = mean_squared_error(y_test, predictions)  # Calculate mean squared error\n",
    "    return model, mse  # Return the trained model and the error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for Random Forest model training and evaluation\n",
    "def random_forest(X_train, y_train, X_test, y_test):\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=42)  # Initialize the Random Forest model\n",
    "    model.fit(X_train, y_train)  # Fit the model to the training data\n",
    "    predictions = model.predict(X_test)  # Make predictions on the test set\n",
    "    mse = mean_squared_error(y_test, predictions)  # Calculate mean squared error\n",
    "    return model, mse  # Return the trained model and the error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for XGBoost model training and evaluation\n",
    "def xgboost_model(X_train, y_train, X_test, y_test):\n",
    "    model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, random_state=42)  # Initialize the XGBoost model\n",
    "    model.fit(X_train, y_train)  # Fit the model to the training data\n",
    "    predictions = model.predict(X_test)  # Make predictions on the test set\n",
    "    mse = mean_squared_error(y_test, predictions)  # Calculate mean squared error\n",
    "    return model, mse  # Return the trained model and the error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to evaluate models using MSE and R² metrics\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    predictions = model.predict(X_test)  # Make predictions on the test set\n",
    "    mse = mean_squared_error(y_test, predictions)  # Calculate mean squared error\n",
    "    r2 = r2_score(y_test, predictions)  # Calculate R² score\n",
    "    return {\"mse\": mse, \"r2\": r2}  # Return the evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to explain model predictions using SHAP\n",
    "def explain_model_shap(model, X_train):\n",
    "    explainer = shap.Explainer(model, X_train)  # Initialize SHAP explainer with the model\n",
    "    shap_values = explainer(X_train)  # Calculate SHAP values for the training data\n",
    "    shap.summary_plot(shap_values, X_train)  # Create a summary plot of SHAP values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train models, then evaluate their performance\n",
    "lr_model, mse_lr = linear_regression(X_train, y_train, X_test, y_test)\n",
    "dt_model, mse_dt = decision_tree(X_train, y_train, X_test, y_test)\n",
    "rf_model, mse_rf = random_forest(X_train, y_train, X_test, y_test)\n",
    "xgb_model, mse_xgb = xgboost_model(X_train, y_train, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alpha_insurance_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
